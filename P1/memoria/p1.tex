\documentclass[11pt,a4paper]{article}

\usepackage[spanish]{babel}
\usepackage[math,light]{iwona}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm}
\usepackage{amsfonts, amssymb, latexsym}
\usepackage{enumerate}
\usepackage[usenames, dvipsnames]{color}
\usepackage{graphics,graphicx, float} %para incluir imágenes y colocarlas
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[top=4cm]{geometry}
\usepackage{cite}
\usepackage[official]{eurosym}
\usepackage{cancel}
\usepackage{subfigure}
\usepackage{minted}

\theoremstyle{plain}
\newtheorem{exe}{Ejercicio} % reset theorem numbering for each chapter

\theoremstyle{definition}
\newtheorem{sol}{Solución}

\usepackage[bookmarks=true,
            bookmarksnumbered=false, % true means bookmarks in
                                     % left window are numbered
            bookmarksopen=false,     % true means only level 1
                                     % are displayed.
            colorlinks=true,
            linkcolor=webblue,
            citecolor=red]{hyperref}
\definecolor{webgreen}{rgb}{0, 0.5, 0} % less intense green
\definecolor{webblue}{rgb}{0, 0, 0.5}  % less intense blue
\definecolor{webred}{rgb}{0.5, 0, 0}   % less intense red

\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\title{\Huge{Visión por Computador} \\ Práctica 1}
\author{Marta Gómez Macías}

\begin{document}

\maketitle

\tableofcontents

\section{Ejercicio A}
\subsection{Cálculo del vector máscara}

A continuación se muestran las funciones encargadas de calcular la máscara:

\begin{minted}[frame=lines, label={Cálculo de la máscara}]{python}
# función gaussiana para la máscara
kernel = lambda x, sigma: exp(-0.5 * ((x*x)/(sigma*sigma)))

# Función para calcular la máscara/kernel
def my_getGaussianKernel(sigma):
    # El tamaño de la máscara depende de sigma. Aplicando la estadística báisca, 
    # llegamos a que lo óptimo es tomar 3sigma por cada lado. Por lo que el 
    # tamaño de la máscara será 6sigma + 1
    mascara = np.arange(-floor(3*sigma),floor(3*sigma + 1))
    # aplicamos la gaussiana a la máscara
    mascara = np.array([kernel(m, sigma) for m in mascara])
    # y la devolvemos normalizada
    return np.divide(mascara, np.sum(mascara))
\end{minted}

La función \texttt{kernel} es una función auxiliar de la función \texttt{my\_getGaussianKernel}. Ésta última está inspirada en la función de \textit{OpenCV} \texttt{getGaussianKernel} y su función es devolver la máscara que más tarde se usará para filtrar la imagen.

A diferencia de la función \texttt{getGaussianKernel} de \textit{OpenCV}, \texttt{my\_getGaussianKernel} calcula el tamaño de la máscara en función de $\sigma$:

\begin{displaymath}
 M\acute{a}scara = \bigg[\lfloor-3\sigma\rfloor,\lfloor3\sigma\rfloor\bigg]
\end{displaymath}

por ejemplo, si $\sigma = 1$, la máscara tendría tamaño 7 y abarcaría el intervalo $[-3,3]$. El redondeo es necesario ya que $\sigma$ es un número real, pero la máscara sólo puede abarcar números enteros.

Una vez que la función obtiene el tamaño de la máscara, pasa a calcular cada valor de la misma. Para ello, se usa la siguiente expresión matemática definida en la función \texttt{kernel}:

\begin{displaymath}
 f(x) = exp \Bigg(-0.5 \cdot \frac{x^2}{\sigma^2} \Bigg)
 \end{displaymath}

Y, por último, la función normaliza los valores obtenidos para que la suma total de la máscara sea 1.

\subsection{Convolución 2D con un filtro Gaussiano}
\subsubsection{Convolución 1D de dos vectores}

En el caso de la gaussiana, la correlación y la convolución obtienen el mismo resultado. Aprovechando esta propiedad, se ha implementado sólo la correlación.

\begin{minted}[frame=lines, label={Correlación de dos vectores 1D}]{python}
# Función para aplicar el kernel a un trocito de imagen
apply_kernel = lambda original, kernel: np.sum(original * kernel)
\end{minted}

Gracias a la librería \texttt{numpy} de python y a las funciones $\lambda$ podemos implementar esta función en una sola línea.

\subsubsection{Relleno de los extemos de la imagen usando distintos criterios de borde}

Para poder elegir distintos tipos de borde, se ha implementado una función "interfaz" que aplica el tipo de borde que escojamos.

\begin{minted}[frame=lines, label={Añadir borde a una imagen}]{python}
# Función para añadir borde a una imagen
def my_copyMakeBorder(src, space, borderType):
    return {
        'black':black_border(src, space),
        'replicate':replicate_border(src,space),
        'reflect':reflect_border(src,space),
        'reflect_101':reflect_101_border(src,space),
        'wrap':wrap_border(src,space)
    }.get(borderType)
\end{minted}

Se han implementado los mismos tipos de bordes que implementa \textit{OpenCV}:

\begin{enumerate}[$\qquad\bullet$]
\item \textbf{Constante}: aplica un borde negro a la imagen. En la \hyperref[black]{Figura \ref*{black}} vemos el resultado de aplicar este tipo de borde a una imagen.

\begin{minted}[frame=lines, label={Borde negro}]{python}
# Función para darle a la imagen un borde negro 
# BORDER_CONSTANT: iiiiii | abcdefgh | iiiiiii
def black_border(src, space):
    # creamos una imagen negra
    if len(src.shape) == 3:
        img_borde = np.zeros((src.shape[0]+space*2, src.shape[1]+space*2,3), \
            np.uint8)
    else:
        img_borde = np.zeros((src.shape[0]+space*2, src.shape[1]+space*2), \
            np.uint8)
    dims = img_borde.shape
    # copiamos en el centro la imagen original
    img_borde[space:dims[0]-space, space:dims[1]-space] = src
    return img_borde
\end{minted}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{borde_negro}
    \caption{Resultado de aplicar la función \texttt{black\_border} sobre una imagen}
    \label{black}
\end{figure}

\item \textbf{Replicado}: copia el último pixel. En la \hyperref[replicate]{Figura \ref*{replicate}} vemos el resultado de aplicar este tipo de borde a una imagen.

\begin{minted}[frame=lines, label={Borde replicado}]{python}
# Función para darle a la imagen un borde 
# BORDER_REPLICATE: aaaaaa | abcdefgh | hhhhhhh
def replicate_border(src, space):
    # le añadimos un borde negro a la imagen
    img_borde = black_border(src,space)
    # cambiamos ese borde negro por una copia del último píxel. Primero por filas
    dims = src.shape
    for fila in range(dims[0]):
        img_borde[space+fila,0:space] = src[fila,0]
        img_borde[space+fila,dims[1]+space:dims[1]+2*space] = src[fila,dims[1]-1]
    # después, por columnas
    for columna in range(dims[1]):
        img_borde[0:space,columna+space] = src[0,columna]
        img_borde[dims[0]+space:dims[0]+2*space,space+columna] = \
        src[dims[0]-1,columna]
    return img_borde
\end{minted}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{borde_replicado}
    \caption{Resultado de aplicar la función \texttt{replicate\_border} sobre una imagen}
    \label{replicate}
\end{figure}

\item \textbf{Reflejado}: refleja en el borde los últimos píxeles de la imagen. En la \hyperref[reflect]{Figura \ref*{reflect}} vemos el resultado de aplicar este tipo de borde a una imagen.

\begin{minted}[frame=lines, label={Borde reflejado}]{python}
# Función para reflejar la imagen
# BORDER_REFLECT: fedcba | abcdefgh | hgfedcb
def reflect_border(src,space):
    # le añadimos un borde negro a la imagen
    img_borde = black_border(src,space)
    # cambiamos ese borde negro por copias de los space primeros píxeles 
    # de la imagen
    dims = src.shape
    for fila in range(dims[0]):
        to_copy_left = np.array(src[fila, 0:space])
        img_borde[space + fila, 0:space] = to_copy_left[::-1]
        to_copy_right = src[fila, dims[1]-space-1:dims[1] - 1]
        img_borde[space + fila, dims[1] + space:dims[1] + 2 * space] = \
        to_copy_right[::-1]

    for columna in range(dims[1]):
        to_copy_left = np.array(src[0:space, columna])
        img_borde[0:space, columna + space] = to_copy_left[::-1]
        to_copy_right = np.array(src[dims[0]-space-1:dims[0] - 1, columna])
        img_borde[dims[0] + space:dims[0] + 2 * space, space + columna] = \
        to_copy_right[::-1]
    return img_borde
\end{minted}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{borde_reflejado}
    \caption{Resultado de aplicar la función \texttt{reflect\_border} sobre una imagen}
    \label{reflect}
\end{figure}

\item \textbf{Reflejado 101}: igual que la anterior, pero empieza a reflejar desde el penúltimo píxel. En la \hyperref[reflect101]{Figura \ref*{reflect101}} vemos el resultado de aplicar este tipo de borde a una imagen.

\begin{minted}[frame=lines, label={Borde reflejado 101}]{python}
# Función para reflejar la imagen
# BORDER_REFLECT_101: gfedcb | abcdefgh| gfedcba
def reflect_101_border(src,space):
    # le añadimos un borde negro a la imagen
    img_borde = black_border(src,space)
    # cambiamos ese borde por los space+1 primeros píxeles de 
    # la imagen, sin contar el primero de todos
    dims = src.shape
    for fila in range(dims[0]):
        to_copy_left = np.array(src[fila, 1:space+1])
        img_borde[space + fila, 0:space] = to_copy_left[::-1]
        to_copy_right = src[fila, dims[1]-space-2:dims[1] - 2]
        img_borde[space + fila, dims[1] + space:dims[1] + 2 * space] = \
        to_copy_right[::-1]

    for columna in range(dims[1]):
        to_copy_left = np.array(src[1:space+1, columna])
        img_borde[0:space, columna + space] = to_copy_left[::-1]
        to_copy_right = np.array(src[dims[0]-space-2:dims[0] - 2, columna])
        img_borde[dims[0] + space:dims[0] + 2 * space, space + columna] = \
        to_copy_right[::-1]
    return img_borde
\end{minted}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{borde_reflejado101}
    \caption{Resultado de aplicar la función \texttt{reflect\_101\_border} sobre una imagen}
    \label{reflect101}
\end{figure}

\item \textbf{Envuelto}: refleja los últimos píxeles del lado contrario. En la \hyperref[wrap]{Figura \ref*{wrap}} vemos el resultado de aplicar este tipo de borde a una imagen.

\begin{minted}[frame=lines, label={Borde envuelto}]{python}
# Función que continua el borde que la imagen deja por el lado contrario
# BORDER_WRAP: cdefgh | abcdefgh | abcdefg
def wrap_border(src,space):
    # le añadimos un borde negro a la imagen
    img_borde = black_border(src, space)
    # cambiamos ese borde negro por copias de los space primeros 
    # píxeles de la imagen
    dims = src.shape
    for fila in range(dims[0]):
        to_copy_left = np.array(src[fila, 0:space])
        to_copy_right = src[fila, dims[1] - space - 1:dims[1] - 1]
        img_borde[space + fila, 0:space] = to_copy_right[::-1]
        img_borde[space + fila, dims[1] + space:dims[1] + 2 * space] = \
        to_copy_left[::-1]

    for columna in range(dims[1]):
        to_copy_left = np.array(src[0:space, columna])
        to_copy_right = np.array(src[dims[0] - space - 1:dims[0] - 1, columna])
        img_borde[0:space, columna + space] = to_copy_right[::-1]
        img_borde[dims[0] + space:dims[0] + 2 * space, space + columna] = \
        to_copy_left[::-1]
    return img_borde
\end{minted}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.7\textwidth]{borde_wrap}
    \caption{Resultado de aplicar la función \texttt{wrap\_border} sobre una imagen}
    \label{wrap}
\end{figure}
\end{enumerate}

Como se aprecia, no se aplica el borde a los píxeles de las esquinas. Este detalle se ha obviado debido a que las esquinas no influyen en el cálculo de la convolución de la imagen.

\subsubsection{Aplicar las funciones anteriores a una imagen separando canales si fuese necesario}

Se han desarrollado dos funciones: \texttt{my\_filter2D} y \texttt{my\_filter2D\_onechannel}. La primera función sirve como interfaz de la segunda.

\begin{minted}[frame=lines, label={Convolución 2D}]{python}
# Función para aplicar la máscara 1D a una imagen con más de un canal
def my_filter2D(src, kernel, borderType):
    # en primer lugar comprobamos si la imagen es en color o en blanco y negro
    if len(src.shape) == 3:
        # si es en color, debemos separar sus canales
        canales = cv2.split(src)
        # y aplicar sobre cada uno de ellos el filtro
        for i in range(len(canales)):
            canales[i] = my_filter2D_onechannel(src=canales[i], kernel=kernel,\
                borderType=borderType)
        # una vez hecho esto, los volvemos a juntar con merge
        img = cv2.merge(canales)
    else:
        # si solo tiene un canal, aplicamos directamente el filtro
        img = my_filter2D_onechannel(src=src, kernel=kernel, \
            borderType=borderType)
    return img

# Función para aplicar la máscara 1D a un canal de la imagen
def my_filter2D_onechannel(src, kernel, borderType):
    mitad_mascara = floor(kernel.size/2)
    # En primer lugar, añadimos bordes a la imagen
    img_bordes = my_copyMakeBorder(src=src, space=mitad_mascara, borderType=borderType)
    img_aux = np.ones(img_bordes.shape, np.uint8)*255
    # Después, aplicamos el kernel a cada trocito
    for j in range(mitad_mascara, img_bordes.shape[0]-mitad_mascara):
        for i in range(mitad_mascara,img_bordes.shape[1]-mitad_mascara):
            img_aux[j,i] = apply_kernel(img_bordes[j,i-mitad_mascara:\
                i+1+mitad_mascara], kernel)
    img_bordes = img_aux.copy(order='F')
    img_aux = np.ones(img_bordes.shape, np.uint8)*255
    # Después, aplicamos el kernel a cada trocito
    for j in range(mitad_mascara, img_bordes.shape[1]-mitad_mascara):
        for i in range(mitad_mascara,img_bordes.shape[0]-mitad_mascara):
            img_aux[i,j] = apply_kernel(img_bordes[i-mitad_mascara:\
                i+1+mitad_mascara,j], kernel)
    img_bordes = img_aux.copy(order='F')
    # Devolvemos la imagen con el filtro aplicado
    return img_bordes[mitad_mascara:-mitad_mascara, mitad_mascara:-mitad_mascara]
\end{minted}

La función \texttt{my\_filter2D} comprueba en primer lugar si la imagen es en color o en blanco y negro. Para ello, comprueba el tamaño del atributo \texttt{shape} de la imagen de entrada. A continuación, si la imagen resulta ser en color, separa sus canales usando la función \texttt{split} de \textit{OpenCV} y aplica el filtro gaussiano sobre cada canal. Por último, una vez aplicado el filtro sobre cada canal, se vuelven a juntar en una sola imagen usando la función \texttt{merge} de \textit{OpenCV}. Si la imagen resulta ser en blanco y negro, se le aplica directamente el filtro.

La función \texttt{my\_filter2D\_onechannel} es la que aplica el filtro sobre un único canal. Para ello, calcula en primer lugar la mitad del tamaño de la máscara para saber el espacio que tiene que dejar en cada borde la imagen. Tras esto, aplica un borde (especificado por parámetro) a la imagen. Usando la imagen con bordes, empezamos a aplicar el filtro a la imagen usando la función \texttt{apply\_kernel}, primero por filas y después por columnas. Es importante destarcar que el filtro debe aplicarse sobre una imagen copia auxiliar para no arrastrar el filtro a lo largo de toda la imagen.

En \hyperref[convolucion]{Figura \ref*{convolucion}} se muesta cómo funciona la función con $\sigma = 1$ y se compara con el resultado que obtiene \textit{OpenCV} con el mismo parámetro. La función desarrollada desenfoca la imagen algo más de lo que hace \textit{OpenCV} pero ambas obtienen un resultado muy similar.

\begin{figure}[!h]
    \centering
    \mbox {
    \subfigure[Resultado obtenido con la función \texttt{getGaussianKernel} de \textit{OpenCV}, usando como parámetros $k_{size} = 7$ y $\sigma=1$]{
    \label{opencv1}
    \includegraphics[width=0.5\textwidth]{opencv_sigma2}
    }
    \qquad
    \subfigure[Resultado obtenido con la función \texttt{my\_getGaussianKernel}, usando como parámetro $\sigma=1$] {
    \label{propio1}
    \includegraphics[width=0.5\textwidth]{propio_sigma2}
    }
    }
    \mbox{
    \subfigure[Resultado obtenido con la función \texttt{getGaussianKernel} de \textit{OpenCV}, usando como parámetros $k_{size} = 19$ y $\sigma=3$]{
    \label{opencv1}
    \includegraphics[width=0.5\textwidth]{opencv_sigma3}
    }
    \qquad
    \subfigure[Resultado obtenido con la función \texttt{my\_getGaussianKernel}, usando como parámetro $\sigma=3$] {
    \label{propio1}
    \includegraphics[width=0.5\textwidth]{propio_sigma3}
    }
    }
    \caption{Comparación entre el filtro gaussiano de \textit{OpenCV} y el desarrollado para la práctica.}
    \label{convolucion}
\end{figure}

\end{document}
